{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6275c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from ipywidgets import interact, FloatSlider, Dropdown, fixed\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# Словарь файлов и соответствующих им названий столбцов\n",
    "files = {\n",
    "    'tksg.csv': 'TCSG',\n",
    "    'yandex.csv': 'YDEX',\n",
    "    'vk.csv': 'VKCO',\n",
    "    'rostelecom.csv': 'RTKM',\n",
    "    'usd_rub.csv': 'USD_RUB',\n",
    "    'brent.csv': 'Brent',\n",
    "    'bitcoin.csv': 'BTC_USD'\n",
    "}\n",
    "\n",
    "# Чтение и отображение первых и последних 5 строк каждого файла и статистики\n",
    "for file_name, column_name in files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(file_name)\n",
    "        print(f\"\\nСтатистика файла {file_name}:\")\n",
    "        print(f\"Количество строк: {len(df)}\")\n",
    "        print(f\"Количество столбцов: {len(df.columns)}\")\n",
    "        \n",
    "        print(\"\\nПервые 5 строк файла:\")\n",
    "        print(df.head())\n",
    "        print(\"\\nПоследние 5 строк файла:\")\n",
    "        print(df.tail())\n",
    "        print(\"-\" * 80)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Файл {file_name} не найден\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при чтении файла {file_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463607e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 обьединение данных в единый временной ряд методом inner join\n",
    "\n",
    "# Функция для конвертации строк с числами в float\n",
    "def convert_to_float(value):\n",
    "    try:\n",
    "        # Удаляем точку как разделитель тысяч и заменяем запятую на точку для десятичного разделителя\n",
    "        cleaned_value = str(value).replace('.', '').replace(',', '.')\n",
    "        return float(cleaned_value)\n",
    "    except (ValueError, TypeError):\n",
    "        return value  # Возвращаем исходное значение, если конвертация не удалась\n",
    "\n",
    "# Создание единого датафрейма final_df\n",
    "dfs = []\n",
    "for file_name, column_name in files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(file_name)\n",
    "        # Выбираем только нужные столбцы и переименовываем столбец с ценой\n",
    "        df = df[['Дата', 'Цена']].rename(columns={'Цена': column_name})\n",
    "        dfs.append(df)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Файл {file_name} не найден\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при чтении файла {file_name}: {str(e)}\")\n",
    "\n",
    "# Объединение всех датафреймов\n",
    "if dfs:\n",
    "    # Начинаем с первого датафрейма\n",
    "    final_df = dfs[0]\n",
    "    # Последовательно объединяем с остальными\n",
    "    for df in dfs[1:]:\n",
    "        final_df = pd.merge(final_df, df, on='Дата', how='inner')\n",
    "    \n",
    "    # Сортировка по дате\n",
    "    final_df['Дата'] = pd.to_datetime(final_df['Дата'], format='%d.%m.%Y')\n",
    "    final_df = final_df.sort_values('Дата')\n",
    "    \n",
    "    # Преобразование данных в числовой формат\n",
    "    for column in final_df.columns:\n",
    "        if column != 'Дата':\n",
    "            final_df[column] = final_df[column].apply(convert_to_float)\n",
    "    \n",
    "    # Вывод информации и статистики до очистки\n",
    "    print(\"\\nИтоговый датафрейм:\")\n",
    "    print(\"\\nПервые 5 строк:\")\n",
    "    print(final_df.head())\n",
    "    print(\"\\nПоследние 5 строк:\")\n",
    "    print(final_df.tail())\n",
    "    print(\"\\nИнформация о датафрейме:\")\n",
    "    print(final_df.info())\n",
    "    print(\"\\nСтатистика датафрейма:\")\n",
    "    print(final_df.describe())\n",
    "    \n",
    "    # Построение графика\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Нормализация данных (приведение к базе 100)\n",
    "    normalized_df = final_df.copy()\n",
    "    for column in normalized_df.columns:\n",
    "        if column != 'Дата':\n",
    "            normalized_df[column] = normalized_df[column] / normalized_df[column].iloc[0] * 100\n",
    "    \n",
    "    # Построение графика для каждого актива\n",
    "    for column in normalized_df.columns:\n",
    "        if column != 'Дата':\n",
    "            plt.plot(normalized_df['Дата'], normalized_df[column], label=column)\n",
    "    \n",
    "    plt.title('Динамика активов (база 100)')\n",
    "    plt.xlabel('Дата')\n",
    "    plt.ylabel('Значение (база 100)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Не удалось создать датафрейм из-за ошибок при чтении файлов\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очистка от выбросов (менее строгая: удаляем строки, где ВСЕ столбцы являются выбросами)\n",
    "def remove_outliers(df, columns):\n",
    "    mask = pd.Series(True, index=df.index)  # Изначально все строки включены\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        # Обновляем маску: строка остается, если значение в столбце НЕ является выбросом\n",
    "        mask = mask & (df[col].between(lower_bound, upper_bound))\n",
    "    return df[mask]\n",
    "\n",
    "# Очистка от выбросов\n",
    "columns_to_clean = list(files.values())\n",
    "cleaned_df = remove_outliers(final_df, columns_to_clean)\n",
    "\n",
    "# Статистика после очистки\n",
    "print(\"\\nИтоговый датафрейм после очистки от выбросов:\")\n",
    "print(\"\\nПервые 5 строк:\")\n",
    "print(cleaned_df.head())\n",
    "print(\"\\nПоследние 5 строк:\")\n",
    "print(cleaned_df.tail())\n",
    "print(\"\\nСтатистика после очистки:\")\n",
    "print(cleaned_df.info())\n",
    "# print(cleaned_df.describe())\n",
    "\n",
    "# Построение графика для очищенных данных\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Нормализация данных (приведение к базе 100) для очищенного датафрейма\n",
    "normalized_df = cleaned_df.copy()\n",
    "for column in normalized_df.columns:\n",
    "    if column != 'Дата':\n",
    "        normalized_df[column] = normalized_df[column] / normalized_df[column].iloc[0] * 100\n",
    "\n",
    "# Построение графика для каждого актива\n",
    "for column in normalized_df.columns:\n",
    "    if column != 'Дата':\n",
    "        plt.plot(normalized_df['Дата'], normalized_df[column], label=column)\n",
    "\n",
    "plt.title('Динамика активов (база 100, после очистки от выбросов)')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Значение (база 100)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1516a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Нормализация (Z-нормализация)\n",
    "# normalized_df = final_df.copy()\n",
    "# for col in columns_to_clean:\n",
    "#     mean = final_df[col].mean()\n",
    "#     std = final_df[col].std()\n",
    "#     normalized_df[col] = (final_df[col] - mean) / std\n",
    "#     print(f\"\\nСтатистика для {col} (до нормализации): mean = {mean:.2f}, std = {std:.2f}\")\n",
    "\n",
    "\n",
    "normalized_df = cleaned_df.copy()\n",
    "for col in columns_to_clean:\n",
    "    mean = cleaned_df[col].mean()\n",
    "    std = cleaned_df[col].std()\n",
    "    normalized_df[col] = (cleaned_df[col] - mean) / std\n",
    "    print(f\"\\nСтатистика для {col} (до нормализации): mean = {mean:.2f}, std = {std:.2f}\")\n",
    "\n",
    "print(\"\\nПример нормализованного датафрейма (первые 5 строк):\")\n",
    "print(normalized_df.head())\n",
    "print(\"\\nСтатистика после нормализации:\")\n",
    "print(normalized_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277bfae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. тест шапиро уилка\n",
    "factors = ['TCSG', 'YDEX', 'VKCO', 'RTKM', 'USD_RUB', 'Brent', 'BTC_USD']\n",
    "normality_results = []\n",
    "distribution_stats = []\n",
    "\n",
    "for factor in factors:\n",
    "    data = normalized_df[factor].dropna()\n",
    "    # Тест Шапиро-Уилка\n",
    "    stat, p_value = stats.shapiro(data)\n",
    "    conclusion = \"Не соответствует нормальному распределению\" if p_value < 0.05 else \"Соответствует нормальному распределению\"\n",
    "    normality_results.append([factor, stat, p_value, conclusion])\n",
    "\n",
    "    # Характеристики распределения\n",
    "    skewness = stats.skew(data)\n",
    "    kurtosis = stats.kurtosis(data)\n",
    "    mean = data.mean()\n",
    "    median = data.median()\n",
    "    std = data.std()\n",
    "    min_val = data.min()\n",
    "    max_val = data.max()\n",
    "    q1 = data.quantile(0.25)\n",
    "    q3 = data.quantile(0.75)\n",
    "    \n",
    "    # Интерпретация асимметрии\n",
    "    skewness_comment = (\n",
    "        \"Сильная правосторонняя асимметрия\" if skewness > 1 else\n",
    "        \"Сильная левосторонняя асимметрия\" if skewness < -1 else\n",
    "        \"Умеренная асимметрия\" if abs(skewness) > 0.5 else\n",
    "        \"Приблизительно симметричное распределение\"\n",
    "    )\n",
    "    \n",
    "    # Интерпретация куртозиса\n",
    "    kurtosis_comment = (\n",
    "        \"Тяжёлые хвосты (много выбросов)\" if kurtosis > 3 else\n",
    "        \"Лёгкие хвосты (меньшая вероятность экстремальных значений, что положительно для моделирования)\" if kurtosis < -1 else\n",
    "        \"Нормальные хвосты (умеренное количество выбросов)\"\n",
    "    )\n",
    "    \n",
    "    # Дополнительные комментарии для факторов\n",
    "    factor_comment = (\n",
    "        \"Высокая волатильность из-за влияния криптовалютного рынка и санкций.\" if factor == 'TCSG' else\n",
    "        \"Зависимость от сырьевых рынков (нефть) и макроэкономической среды.\" if factor in ['YDEX', 'VKCO', 'RTKM'] else\n",
    "        \"Волатильность связана с экономическими и геополитическими факторами.\" if factor == 'USD_RUB' else\n",
    "        \"Зависимость от мировых сырьевых рынков.\" if factor == 'Brent' else\n",
    "        \"Высокая волатильность из-за спекулятивного характера криптовалют.\"\n",
    "    )\n",
    "    \n",
    "    distribution_stats.append([\n",
    "        factor, mean, median, std, skewness, kurtosis, min_val, max_val, q1, q3,\n",
    "        skewness_comment, kurtosis_comment, factor_comment\n",
    "    ])\n",
    "\n",
    "# Формирование таблиц результатов\n",
    "normality_df = pd.DataFrame(normality_results, columns=['Фактор', 'Статистика Шапиро-Уилка', 'p-value', 'Нормальность'])\n",
    "dist_stats_df = pd.DataFrame(distribution_stats, columns=[\n",
    "    'Фактор', 'Среднее', 'Медиана', 'Стд. откл.', 'Асимметрия', 'Куртозис',\n",
    "    'Мин.', 'Макс.', 'Q1', 'Q3', 'Асимметрия (пояснение)', 'Куртозис (пояснение)', 'Комментарий'\n",
    "]).round(4)\n",
    "\n",
    "# Вывод таблиц\n",
    "print(\"\\nРезультаты теста Шапиро-Уилка:\")\n",
    "print(normality_df.to_string(index=False))\n",
    "# print(\"\\nХарактеристики распределения:\")\n",
    "# print(dist_stats_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0255018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Корреляционный анализ \n",
    "def analyze_correlations():\n",
    "    print(\"\\n=== Корреляционный анализ (метод Спирмена) ===\")\n",
    "    \n",
    "    # Корреляция Спирмена\n",
    "    correlation_matrix = normalized_df[columns_to_clean].corr(method='spearman')\n",
    "    \n",
    "    # # Форматирование матрицы для вывода\n",
    "    # corr_df = correlation_matrix.round(3)  # Округляем до 3 знаков после запятой\n",
    "    # print(\"\\nМатрица корреляции (Спирмен):\")\n",
    "    # display(corr_df.style.background_gradient(cmap='coolwarm', axis=None).set_caption('Корреляционная матрица (Спирмен)'))\n",
    "\n",
    "    # Визуализация корреляции\n",
    "    plt.figure(figsize=(10, 8), dpi=100)\n",
    "    plt.matshow(correlation_matrix, cmap='coolwarm', fignum=1)\n",
    "    plt.xticks(range(len(columns_to_clean)), columns_to_clean, rotation=45, ha='left')\n",
    "    plt.yticks(range(len(columns_to_clean)), columns_to_clean)\n",
    "    for (i, j), val in np.ndenumerate(correlation_matrix):\n",
    "        plt.text(j, i, f'{val:.2f}', ha='center', va='center', color='black', fontsize=10)\n",
    "    plt.title('Корреляция Спирмена', fontsize=14, pad=20)\n",
    "    plt.colorbar(label='Коэффициент корреляции')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Выполняем корреляционный анализ\n",
    "analyze_correlations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead1abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Модель линейной регрессии\n",
    "dependent_vars = ['TCSG', 'YDEX', 'VKCO', 'RTKM']\n",
    "independent_vars = ['USD_RUB', 'Brent', 'BTC_USD']\n",
    "\n",
    "results_normalized = {}  # Линейная регрессия\n",
    "X_normalized = normalized_df[independent_vars].dropna()\n",
    "\n",
    "for y_var in dependent_vars:\n",
    "    y = normalized_df[y_var].dropna()\n",
    "    common_index = X_normalized.index.intersection(y.index)\n",
    "    X_subset = X_normalized.loc[common_index]\n",
    "    y_subset = y.loc[common_index]\n",
    "    \n",
    "    # Разбиение данных\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Линейная регрессия\n",
    "    model_lr = LinearRegression()\n",
    "    model_lr.fit(X_train, y_train)\n",
    "    y_pred_lr = model_lr.predict(X_test)\n",
    "    mae_lr = np.mean(np.abs(y_test - y_pred_lr))\n",
    "    mse_lr = np.mean((y_test - y_pred_lr) ** 2)\n",
    "    \n",
    "    results_normalized[y_var] = {\n",
    "        'y_actual': y_test,\n",
    "        'y_pred': y_pred_lr,\n",
    "        'X_test': X_test,\n",
    "        'model': model_lr,\n",
    "        'coefficients': dict(zip(independent_vars, model_lr.coef_)),\n",
    "        'intercept': model_lr.intercept_,\n",
    "        'MAE': mae_lr,\n",
    "        'MSE': mse_lr\n",
    "    }\n",
    "    \n",
    "# Формирование таблицы регрессии\n",
    "results_data = []\n",
    "for y_var in dependent_vars:\n",
    "    coeffs = results_normalized[y_var]['coefficients']\n",
    "    results_data.append([\n",
    "        y_var,\n",
    "        coeffs.get('USD_RUB', 0),\n",
    "        coeffs.get('Brent', 0),\n",
    "        coeffs.get('BTC_USD', 0),\n",
    "        results_normalized[y_var]['intercept'],\n",
    "        results_normalized[y_var]['MAE'],\n",
    "        results_normalized[y_var]['MSE']\n",
    "    ])\n",
    "results_df = pd.DataFrame(\n",
    "    results_data,\n",
    "    columns=['Компания', 'USD_RUB (β1)', 'Brent (β2)', 'BTC_USD (β3)', 'Intercept', 'MAE', 'MSE']\n",
    ").round(4)\n",
    "\n",
    "print(\"\\nРезультаты линейной регрессии (на тестовой выборке):\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Анализ ошибок регрессии\n",
    "print(\"\\nАнализ ошибок линейной регрессии (на тестовой выборке):\")\n",
    "for y_var in dependent_vars:\n",
    "    errors = results_normalized[y_var]['y_actual'] - results_normalized[y_var]['y_pred']\n",
    "    error_mean = errors.mean()\n",
    "    error_std = errors.std()\n",
    "    error_skewness = stats.skew(errors)\n",
    "    error_kurtosis = stats.kurtosis(errors)\n",
    "    \n",
    "    stat, p = stats.shapiro(errors)\n",
    "    normality_comment = \"Ошибки не соответствуют нормальному распределению\" if p < 0.05 else \"Ошибки соответствуют нормальному распределению\"\n",
    "    \n",
    "    error_mean_comment = (\n",
    "        f\"Ошибки в среднем {'смещены вверх' if error_mean > 0.1 else 'смещены вниз' if error_mean < -0.1 else 'близки к нулю'} \"\n",
    "        f\"(среднее: {error_mean:.4f}).\"\n",
    "    )\n",
    "    error_std_comment = (\n",
    "        f\"{'Высокая вариабельность ошибок' if error_std > 1 else 'Умеренная вариабельность ошибок' if error_std > 0.5 else 'Низкая вариабельность ошибок'} \"\n",
    "        f\"(стандартное отклонение: {error_std:.4f}).\"\n",
    "    )\n",
    "    error_skewness_comment = (\n",
    "        \"Сильная правосторонняя асимметрия ошибок\" if error_skewness > 1 else\n",
    "        \"Сильная левосторонняя асимметрия ошибок\" if error_skewness < -1 else\n",
    "        \"Умеренная асимметрия ошибок\" if abs(error_skewness) > 0.5 else\n",
    "        \"Ошибки симметричны\"\n",
    "    )\n",
    "    error_kurtosis_comment = (\n",
    "        \"Тяжёлые хвосты ошибок (много выбросов)\" if error_kurtosis > 3 else\n",
    "        \"Лёгкие хвосты ошибок (меньшая вероятность экстремальных значений)\" if error_kurtosis < -1 else\n",
    "        \"Нормальные хвосты ошибок\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nХарактеристики ошибок для {y_var}:\")\n",
    "    print(f\"- Среднее: {error_mean_comment}\")\n",
    "    print(f\"- Стандартное отклонение: {error_std_comment}\")\n",
    "    print(f\"- Асимметрия: {error_skewness_comment} (значение: {error_skewness:.4f})\")\n",
    "    print(f\"- Куртозис: {error_kurtosis_comment} (значение: {error_kurtosis:.4f})\")\n",
    "    print(f\"- Шапиро-Уилка: stat={stat:.4f}, p={p:.4f}, {normality_comment}\")\n",
    "    \n",
    "    # Гистограмма ошибок\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(errors, kde=True, bins=50, color='purple')\n",
    "    plt.title(f'Распределение ошибок для {y_var} (линейная регрессия)')\n",
    "    plt.xlabel('Ошибка (реальное - предсказанное)')\n",
    "    plt.ylabel('Частота')\n",
    "    plt.xlim(-5, 5)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # График предсказанных vs реальных значений\n",
    "    y_actual = results_normalized[y_var]['y_actual']\n",
    "    y_pred = results_normalized[y_var]['y_pred']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_actual, y_pred, color='blue', alpha=0.5)\n",
    "    plt.plot([y_actual.min(), y_actual.max()], [y_actual.min(), y_actual.max()], 'r--', lw=2)\n",
    "    plt.title(f'Предсказанные vs Реальные значения для {y_var} (линейная регрессия)')\n",
    "    plt.xlabel('Реальные значения (Z-нормализованные)')\n",
    "    plt.ylabel('Предсказанные значения (Z-нормализованные)')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4139456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Модель случайного леса\n",
    "dependent_vars = ['TCSG', 'YDEX', 'VKCO', 'RTKM']\n",
    "independent_vars = ['USD_RUB', 'Brent', 'BTC_USD']\n",
    "\n",
    "results_normalized_rf = {}  # Случайный лес\n",
    "X_normalized = normalized_df[independent_vars].dropna()\n",
    "\n",
    "for y_var in dependent_vars:\n",
    "    y = normalized_df[y_var].dropna()\n",
    "    common_index = X_normalized.index.intersection(y.index)\n",
    "    X_subset = X_normalized.loc[common_index]\n",
    "    y_subset = y.loc[common_index]\n",
    "    \n",
    "    # Разбиение данных\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Случайный лес\n",
    "    model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    y_pred_rf = model_rf.predict(X_test)\n",
    "    mae_rf = np.mean(np.abs(y_test - y_pred_rf))\n",
    "    mse_rf = np.mean((y_test - y_pred_rf) ** 2)\n",
    "    \n",
    "    results_normalized_rf[y_var] = {\n",
    "        'y_actual': y_test,\n",
    "        'y_pred': y_pred_rf,\n",
    "        'X_test': X_test,\n",
    "        'model': model_rf,\n",
    "        'feature_importances': dict(zip(independent_vars, model_rf.feature_importances_)),\n",
    "        'MAE': mae_rf,\n",
    "        'MSE': mse_rf\n",
    "    }\n",
    "    \n",
    "# Формирование таблицы для случайного леса\n",
    "results_data_rf = []\n",
    "for y_var in dependent_vars:\n",
    "    importances = results_normalized_rf[y_var]['feature_importances']\n",
    "    results_data_rf.append([\n",
    "        y_var,\n",
    "        importances.get('USD_RUB', 0),\n",
    "        importances.get('Brent', 0),\n",
    "        importances.get('BTC_USD', 0),\n",
    "        results_normalized_rf[y_var]['MAE'],\n",
    "        results_normalized_rf[y_var]['MSE']\n",
    "    ])\n",
    "results_df_rf = pd.DataFrame(\n",
    "    results_data_rf,\n",
    "    columns=['Компания', 'USD_RUB (важность)', 'Brent (важность)', 'BTC_USD (важность)', 'MAE', 'MSE']\n",
    ").round(4)\n",
    "\n",
    "print(\"\\nРезультаты случайного леса (на тестовой выборке):\")\n",
    "print(results_df_rf.to_string(index=False))\n",
    "\n",
    "# Анализ ошибок случайного леса\n",
    "print(\"\\nАнализ ошибок случайного леса (на тестовой выборке):\")\n",
    "for y_var in dependent_vars:\n",
    "    errors = results_normalized_rf[y_var]['y_actual'] - results_normalized_rf[y_var]['y_pred']\n",
    "    error_mean = errors.mean()\n",
    "    error_std = errors.std()\n",
    "    error_skewness = stats.skew(errors)\n",
    "    error_kurtosis = stats.kurtosis(errors)\n",
    "    \n",
    "    stat, p = stats.shapiro(errors)\n",
    "    normality_comment = \"Ошибки не соответствуют нормальному распределению\" if p < 0.05 else \"Ошибки соответствуют нормальному распределению\"\n",
    "    \n",
    "    error_mean_comment = (\n",
    "        f\"Ошибки в среднем {'смещены вверх' if error_mean > 0.1 else 'смещены вниз' if error_mean < -0.1 else 'близки к нулю'} \"\n",
    "        f\"(среднее: {error_mean:.4f}).\"\n",
    "    )\n",
    "    error_std_comment = (\n",
    "        f\"{'Высокая вариабельность ошибок' if error_std > 1 else 'Умеренная вариабельность ошибок' if error_std > 0.5 else 'Низкая вариабельность ошибок'} \"\n",
    "        f\"(стандартное отклонение: {error_std:.4f}).\"\n",
    "    )\n",
    "    error_skewness_comment = (\n",
    "        \"Сильная правосторонняя асимметрия ошибок\" if error_skewness > 1 else\n",
    "        \"Сильная левосторонняя асимметрия ошибок\" if error_skewness < -1 else\n",
    "        \"Умеренная асимметрия ошибок\" if abs(error_skewness) > 0.5 else\n",
    "        \"Ошибки симметричны\"\n",
    "    )\n",
    "    error_kurtosis_comment = (\n",
    "        \"Тяжёлые хвосты ошибок (много выбросов)\" if error_kurtosis > 3 else\n",
    "        \"Лёгкие хвосты ошибок (меньшая вероятность экстремальных значений)\" if error_kurtosis < -1 else\n",
    "        \"Нормальные хвосты ошибок\"\n",
    "    )\n",
    "    \n",
    "    # print(f\"\\nХарактеристики ошибок для {y_var}:\")\n",
    "    # print(f\"- Среднее: {error_mean_comment}\")\n",
    "    # print(f\"- Стандартное отклонение: {error_std_comment}\")\n",
    "    # print(f\"- Асимметрия: {error_skewness_comment} (значение: {error_skewness:.4f})\")\n",
    "    # print(f\"- Куртозис: {error_kurtosis_comment} (значение: {error_kurtosis:.4f})\")\n",
    "    # print(f\"- Шапиро-Уилка: stat={stat:.4f}, p={p:.4f}, {normality_comment}\")\n",
    "    \n",
    "    # # Гистограмма ошибок\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # sns.histplot(errors, kde=True, bins=50, color='purple')\n",
    "    # plt.title(f'Распределение ошибок для {y_var} (случайный лес)')\n",
    "    # plt.xlabel('Ошибка (реальное - предсказанное)')\n",
    "    # plt.ylabel('Частота')\n",
    "    # plt.xlim(-5, 5)\n",
    "    # plt.grid(True)\n",
    "    # plt.show()\n",
    "    \n",
    "    # # График предсказанных vs реальных значений\n",
    "    # y_actual = results_normalized_rf[y_var]['y_actual']\n",
    "    # y_pred = results_normalized_rf[y_var]['y_pred']\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # plt.scatter(y_actual, y_pred, color='blue', alpha=0.5)\n",
    "    # plt.plot([y_actual.min(), y_actual.max()], [y_actual.min(), y_actual.max()], 'r--', lw=2)\n",
    "    # plt.title(f'Предсказанные vs Реальные значения для {y_var} (случайный лес)')\n",
    "    # plt.xlabel('Реальные значения (Z-нормализованные)')\n",
    "    # plt.ylabel('Предсказанные значения (Z-нормализованные)')\n",
    "    # plt.grid(True)\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01153d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. ANOVA анализ \n",
    "print(\"\\nВывод ANOVA для линейной регрессии:\")\n",
    "results_anova = {}\n",
    "for y_var in dependent_vars:\n",
    "    data = normalized_df[[y_var] + independent_vars].dropna()\n",
    "    formula = f'{y_var} ~ USD_RUB + Brent + BTC_USD'\n",
    "    model = ols(formula, data=data).fit()\n",
    "    anova_table = anova_lm(model, typ=2)\n",
    "    results_anova[y_var] = anova_table\n",
    "\n",
    "    print(f\"\\nРезультаты ANOVA для {y_var}:\")\n",
    "    print(results_anova[y_var].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada9fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Функция для бутстрэппинга\n",
    "def bootstrap_regression(X, y, n_bootstraps=1000, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    coefs_bootstrap = []\n",
    "    intercepts_bootstrap = []\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        # Выборка с возвращением\n",
    "        X_boot, y_boot = resample(X, y, random_state=random_state)\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_boot, y_boot)\n",
    "        coefs_bootstrap.append(model.coef_)\n",
    "        intercepts_bootstrap.append(model.intercept_)\n",
    "    \n",
    "    # Преобразуем в массив\n",
    "    coefs_bootstrap = np.array(coefs_bootstrap)\n",
    "    intercepts_bootstrap = np.array(intercepts_bootstrap)\n",
    "    \n",
    "    # Рассчитываем 95%-ные доверительные интервалы\n",
    "    ci_lower = np.percentile(coefs_bootstrap, 2.5, axis=0)\n",
    "    ci_upper = np.percentile(coefs_bootstrap, 97.5, axis=0)\n",
    "    intercept_ci_lower = np.percentile(intercepts_bootstrap, 2.5)\n",
    "    intercept_ci_upper = np.percentile(intercepts_bootstrap, 97.5)\n",
    "    \n",
    "    return coefs_bootstrap.mean(axis=0), ci_lower, ci_upper, intercepts_bootstrap.mean(), intercept_ci_lower, intercept_ci_upper\n",
    "\n",
    "# Проведение бутстрэппинга для каждой зависимой переменной\n",
    "dependent_vars = ['TCSG', 'YDEX', 'VKCO', 'RTKM']\n",
    "independent_vars_full = ['USD_RUB', 'Brent', 'BTC_USD']\n",
    "independent_vars_tcsg = ['USD_RUB', 'BTC_USD']  # Без Brent для TCSG\n",
    "results_bootstrap = {}\n",
    "\n",
    "for y_var in dependent_vars:\n",
    "    print(f\"\\nБутстрэппинг для {y_var}:\")\n",
    "    y = normalized_df[y_var].dropna()\n",
    "    X = normalized_df[independent_vars_full].dropna()\n",
    "    features = independent_vars_full\n",
    "    \n",
    "    common_index = X.index.intersection(y.index)\n",
    "    X_subset = X.loc[common_index]\n",
    "    y_subset = y.loc[common_index]\n",
    "    \n",
    "    if len(common_index) == 0:\n",
    "        print(f\"Warning: No common indices for {y_var}. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # Выполняем бутстрэппинг\n",
    "    mean_coefs, ci_lower, ci_upper, mean_intercept, intercept_ci_lower, intercept_ci_upper = bootstrap_regression(X_subset, y_subset)\n",
    "    \n",
    "    # Формируем результаты\n",
    "    results_bootstrap[y_var] = {\n",
    "        'features': features,\n",
    "        'mean_coefs': dict(zip(features, mean_coefs)),\n",
    "        'ci_lower': dict(zip(features, ci_lower)),\n",
    "        'ci_upper': dict(zip(features, ci_upper)),\n",
    "        'mean_intercept': mean_intercept,\n",
    "        'intercept_ci_lower': intercept_ci_lower,\n",
    "        'intercept_ci_upper': intercept_ci_upper\n",
    "    }\n",
    "    \n",
    "    # Вывод результатов\n",
    "    print(f\"\\nРезультаты для {y_var}:\")\n",
    "    for feature, coef, lower, upper in zip(features, mean_coefs, ci_lower, ci_upper):\n",
    "        significant = \"Значимый\" if (lower > 0 or upper < 0) else \"Незначимый\"\n",
    "        print(f\"{feature}: Коэффициент = {coef:.4f}, 95% CI = [{lower:.4f}, {upper:.4f}] ({significant})\")\n",
    "    print(f\"Intercept: Коэффициент = {mean_intercept:.4f}, 95% CI = [{intercept_ci_lower:.4f}, {intercept_ci_upper:.4f}]\")\n",
    "\n",
    "# Формируем таблицу результатов\n",
    "results_data_bootstrap = []\n",
    "for y_var in dependent_vars:\n",
    "    if y_var not in results_bootstrap:\n",
    "        continue\n",
    "    row = [y_var]\n",
    "    for feature in independent_vars_full:\n",
    "        if feature in results_bootstrap[y_var]['mean_coefs']:\n",
    "            coef = results_bootstrap[y_var]['mean_coefs'][feature]\n",
    "            lower = results_bootstrap[y_var]['ci_lower'][feature]\n",
    "            upper = results_bootstrap[y_var]['ci_upper'][feature]\n",
    "            significant = \"Да\" if (lower > 0 or upper < 0) else \"Нет\"\n",
    "            row.append(f\"{coef:.4f} [{lower:.4f}, {upper:.4f}] ({significant})\")\n",
    "        else:\n",
    "            row.append(\"0.0000 [0.0000, 0.0000] (Незначимый)\")  # Для Brent в TCSG\n",
    "    results_data_bootstrap.append(row)\n",
    "\n",
    "results_df_bootstrap = pd.DataFrame(\n",
    "    results_data_bootstrap,\n",
    "    columns=['Компания', 'USD_RUB', 'Brent', 'BTC_USD']\n",
    ").round(4)\n",
    "\n",
    "print(\"\\nТаблица результатов бутстрэппинга:\")\n",
    "print(results_df_bootstrap.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5510f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Непараметрический дисперсионный анализ Крускала-Уоллиса\n",
    "def categorize_factor(series, bins=3):\n",
    "    labels = ['Низкий', 'Средний', 'Высокий'][:bins]\n",
    "    return pd.cut(series, bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "normalized_df['USD_RUB_cat'] = categorize_factor(normalized_df['USD_RUB'])\n",
    "normalized_df['Brent_cat'] = categorize_factor(normalized_df['Brent'])\n",
    "normalized_df['BTC_USD_cat'] = categorize_factor(normalized_df['BTC_USD'])\n",
    "\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "for y_var in dependent_vars:\n",
    "    print(f\"\\nТест Крускала-Уоллиса для {y_var}:\")\n",
    "    for factor in ['USD_RUB_cat', 'Brent_cat', 'BTC_USD_cat']:\n",
    "\n",
    "        groups = [normalized_df[y_var][normalized_df[factor] == level].dropna() for level in normalized_df[factor].unique()]\n",
    "        stat, p = kruskal(*groups)\n",
    "        print(f\"{factor}: Статистика = {stat:.4f}, p-value = {p:.4f}, \"\n",
    "              f\"{'Значимо' if p < 0.05 else 'Незначимо'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c106936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Непараметрический дисперсионный анализ Крускала-Уоллиса\n",
    "print(\"\\nНепараметрический дисперсионный анализ Крускала-Уоллиса:\")\n",
    "\n",
    "# Создаем список групп для сравнения (например, группы по компаниям)\n",
    "groups = []\n",
    "for y_var in dependent_vars:\n",
    "    groups.append(normalized_df[y_var].dropna())\n",
    "\n",
    "# Проводим тест Крускала-Уоллиса\n",
    "stat, p_value = stats.kruskal(*groups)\n",
    "\n",
    "# Формируем таблицу результатов\n",
    "results_kruskal = pd.DataFrame({\n",
    "    'Тест': ['Крускала-Уоллиса'],\n",
    "    'Статистика': [stat],\n",
    "    'p-value': [p_value],\n",
    "    'Вывод': ['Есть значимые различия между группами' if p_value < 0.05 else 'Нет значимых различий между группами']\n",
    "})\n",
    "\n",
    "# Выводим результаты\n",
    "print(\"\\nРезультаты теста Крускала-Уоллиса для сравнения компаний:\")\n",
    "print(results_kruskal.to_string(index=False))\n",
    "\n",
    "# Дополнительные сравнения для пар групп (пост-хок тест)\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nПост-хок анализ (попарные сравнения):\")\n",
    "    from scipy.stats import mannwhitneyu\n",
    "    from itertools import combinations\n",
    "    \n",
    "    # Коррекция Бонферрони для множественных сравнений\n",
    "    alpha = 0.05\n",
    "    num_comparisons = len(list(combinations(dependent_vars, 2)))\n",
    "    corrected_alpha = alpha / num_comparisons\n",
    "    \n",
    "    comparisons = []\n",
    "    for (group1, group2) in combinations(dependent_vars, 2):\n",
    "        stat, p = mannwhitneyu(normalized_df[group1].dropna(), normalized_df[group2].dropna(), alternative='two-sided')\n",
    "        significant = \"Да\" if p < corrected_alpha else \"Нет\"\n",
    "        comparisons.append([f\"{group1} vs {group2}\", stat, p, corrected_alpha, significant])\n",
    "    \n",
    "    posthoc_df = pd.DataFrame(comparisons, columns=['Сравнение', 'Статистика', 'p-value', 'Скорректированный alpha', 'Значимо'])\n",
    "    print(posthoc_df.to_string(index=False))\n",
    "    \n",
    "    # Интерпретация\n",
    "    print(\"\\nИнтерпретация результатов:\")\n",
    "    print(\"1. Тест Крускала-Уоллиса показывает, есть ли статистически значимые различия между группами в целом.\")\n",
    "    print(f\"2. В данном случае p-value = {p_value:.4f}, что {'меньше' if p_value < 0.05 else 'больше'} 0.05.\")\n",
    "    print(f\"3. Это означает, что {'существуют' if p_value < 0.05 else 'не существуют'} значимые различия между медианами цен акций компаний.\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(\"4. Пост-хок анализ (с поправкой Бонферрони) показывает, между какими именно парами компаний есть различия:\")\n",
    "        for comp in comparisons:\n",
    "            if comp[4] == \"Да\":\n",
    "                print(f\"   - {comp[0]}: p-value = {comp[2]:.4f} (различия значимы)\")\n",
    "else:\n",
    "    print(\"\\nДальнейший пост-хок анализ не требуется, так как не обнаружено значимых различий между группами.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4344bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "#  Updated train_normalized_model to ensure TCSG excludes Brent\n",
    "def train_normalized_model():\n",
    "    try:\n",
    "        independent_vars_tcsg = ['USD_RUB', 'BTC_USD']  # Explicitly exclude Brent for TCSG\n",
    "        independent_vars_full = ['USD_RUB', 'Brent', 'BTC_USD']\n",
    "        X_norm = normalized_df[independent_vars_full].dropna()\n",
    "        X_norm_tcsg = normalized_df[independent_vars_tcsg].dropna()\n",
    "        results_normalized = {}\n",
    "        results_normalized_rf = {}\n",
    "        \n",
    "        for y_var in dependent_vars:\n",
    "            y = normalized_df[y_var].dropna()\n",
    "            if y_var == 'TCSG':\n",
    "                X_subset_full = X_norm_tcsg\n",
    "                features_used = independent_vars_tcsg\n",
    "                # print(f\"Training {y_var} with features: {features_used}\")\n",
    "            else:\n",
    "                X_subset_full = X_norm\n",
    "                features_used = independent_vars_full\n",
    "                # print(f\"Training {y_var} with features: {features_used}\")\n",
    "            common_index = X_subset_full.index.intersection(y.index)\n",
    "            if len(common_index) == 0:\n",
    "                print(f\"Warning: No common indices for {y_var}. Skipping.\")\n",
    "                continue\n",
    "            X_subset = X_subset_full.loc[common_index]\n",
    "            y_subset = y.loc[common_index]\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=0.2, random_state=42)\n",
    "            # print(f\"{y_var} X_train columns: {list(X_train.columns)}\")\n",
    "            # print(f\"{y_var} X_test columns: {list(X_test.columns)}\")\n",
    "            \n",
    "            # Linear Regression\n",
    "            model_lr = LinearRegression()\n",
    "            model_lr.fit(X_train, y_train)\n",
    "            y_pred_lr = model_lr.predict(X_test)\n",
    "            mae_lr = np.mean(np.abs(y_test - y_pred_lr))\n",
    "            mse_lr = np.mean((y_test - y_pred_lr) ** 2)\n",
    "            \n",
    "            if y_var == 'TCSG':\n",
    "                coefs = dict(zip(independent_vars_tcsg, model_lr.coef_))\n",
    "                coefs['Brent'] = 0.0  # Add Brent with 0 coefficient for consistency\n",
    "            else:\n",
    "                coefs = dict(zip(independent_vars_full, model_lr.coef_))\n",
    "            \n",
    "            results_normalized[y_var] = {\n",
    "                'y_actual': y_test,\n",
    "                'y_pred': y_pred_lr,\n",
    "                'X_train': X_train,\n",
    "                'X_test': X_test,\n",
    "                'model': model_lr,\n",
    "                'coefficients': coefs,\n",
    "                'intercept': model_lr.intercept_,\n",
    "                'MAE': mae_lr,\n",
    "                'MSE': mse_lr\n",
    "            }\n",
    "            \n",
    "            # Random Forest\n",
    "            model_rf = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "            model_rf.fit(X_train, y_train)\n",
    "            y_pred_rf = model_rf.predict(X_test)\n",
    "            mae_rf = np.mean(np.abs(y_test - y_pred_rf))\n",
    "            mse_rf = np.mean((y_test - y_pred_rf) ** 2)\n",
    "            \n",
    "            if y_var == 'TCSG':\n",
    "                importances = dict(zip(independent_vars_tcsg, model_rf.feature_importances_))\n",
    "                importances['Brent'] = 0.0  # Add Brent with 0 importance for consistency\n",
    "            else:\n",
    "                importances = dict(zip(independent_vars_full, model_rf.feature_importances_))\n",
    "            \n",
    "            results_normalized_rf[y_var] = {\n",
    "                'y_actual': y_test,\n",
    "                'y_pred': y_pred_rf,\n",
    "                'X_train': X_train,\n",
    "                'X_test': X_test,\n",
    "                'model': model_rf,\n",
    "                'feature_importances': importances,\n",
    "                'MAE': mae_rf,\n",
    "                'MSE': mse_rf\n",
    "            }\n",
    "        \n",
    "        return results_normalized, results_normalized_rf\n",
    "    except Exception as e:\n",
    "        print(f\"Error in train_normalized_model: {e}\")\n",
    "        return {}, {}\n",
    "\n",
    "def predict_prices(usd_rub, brent, btc_usd, data_type, model_type):\n",
    "    try:\n",
    "        predictions = {}\n",
    "        results = results_normalized if model_type == 'Линейная регрессия' else results_normalized_rf\n",
    "        ylabel = 'Цена акций (Z-нормализованная)' if data_type == 'Z-нормализованные' else 'Цена акций (рубли)'\n",
    "        \n",
    "        # Convert inputs to Z-normalized values\n",
    "        usd_rub_norm = usd_rub if data_type == 'Z-нормализованные' else (usd_rub - cleaned_df['USD_RUB'].mean()) / cleaned_df['USD_RUB'].std()\n",
    "        brent_norm = brent if data_type == 'Z-нормализованные' else (brent - cleaned_df['Brent'].mean()) / cleaned_df['Brent'].std()\n",
    "        btc_usd_norm = btc_usd if data_type == 'Z-нормализованные' else (btc_usd - cleaned_df['BTC_USD'].mean()) / cleaned_df['BTC_USD'].std()\n",
    "        \n",
    "        for y_var in dependent_vars:\n",
    "            if y_var not in results:\n",
    "                print(f\"Warning: No model for {y_var}. Skipping prediction.\")\n",
    "                continue\n",
    "                \n",
    "            model = results[y_var]['model']\n",
    "            expected_features = list(results[y_var]['X_test'].columns)\n",
    "            \n",
    "            # Prepare input data based on expected features\n",
    "            if y_var == 'TCSG':\n",
    "                input_data = pd.DataFrame({\n",
    "                    'USD_RUB': [usd_rub_norm],\n",
    "                    'BTC_USD': [btc_usd_norm]\n",
    "                })\n",
    "            else:\n",
    "                input_data = pd.DataFrame({\n",
    "                    'USD_RUB': [usd_rub_norm],\n",
    "                    'Brent': [brent_norm],\n",
    "                    'BTC_USD': [btc_usd_norm]\n",
    "                })\n",
    "            \n",
    "            # Ensure columns match exactly what model expects\n",
    "            input_data = input_data[expected_features]\n",
    "            \n",
    "            prediction = model.predict(input_data)[0]\n",
    "            \n",
    "            # Denormalize prediction if output is in rubles\n",
    "            if data_type == 'Реальные (рубли)':\n",
    "                prediction = prediction * cleaned_df[y_var].std() + cleaned_df[y_var].mean()\n",
    "                prediction = max(0, prediction)  # Ensure non-negative prices\n",
    "            predictions[y_var] = prediction\n",
    "        return predictions, ylabel\n",
    "    except Exception as e:\n",
    "        print(f\"Error in predict_prices: {e}\")\n",
    "        return {}, 'Цена акций'\n",
    "\n",
    "def update_plot(usd_rub, brent, btc_usd, data_type, model_type):\n",
    "    try:\n",
    "        predictions, ylabel = predict_prices(usd_rub, brent, btc_usd, data_type, model_type)\n",
    "        if not predictions:\n",
    "            print(\"No predictions available.\")\n",
    "            return\n",
    "        \n",
    "        # Create bar chart\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        companies = list(predictions.keys())\n",
    "        values = [predictions[company] for company in companies]\n",
    "        bars = plt.bar(companies, values, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "        plt.title(f'Прогнозируемые цены акций ({data_type}, {model_type})', fontsize=14)\n",
    "        plt.xlabel('Компания')\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.grid(True, axis='y')\n",
    "        for bar, value in zip(bars, values):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, value + 0.02 * value, f'{value:.2f}', ha='center', va='bottom')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # print(f\"\\nПрогнозы ({data_type}, {model_type}):\")\n",
    "        # for k, v in predictions.items():\n",
    "        #     print(f\"{k}: {round(v, 2)}\")\n",
    "\n",
    "        # Debug output\n",
    "        # results = results_normalized if model_type == 'Линейная регрессия' else results_normalized_rf\n",
    "        # print(f\"\\nРезультаты модели ({data_type}, {model_type}):\")\n",
    "        # for y_var in dependent_vars:\n",
    "        #     if y_var in results:\n",
    "        #         print(f\"\\n{y_var}:\")\n",
    "        #         if model_type == 'Линейная регрессия':\n",
    "        #             print(f\"  USD_RUB: {results[y_var]['coefficients']['USD_RUB']:.4f}\")\n",
    "        #             print(f\"  Brent: {results[y_var]['coefficients']['Brent']:.4f}\")\n",
    "        #             print(f\"  BTC_USD: {results[y_var]['coefficients']['BTC_USD']:.4f}\")\n",
    "        #             print(f\"  Intercept: {results[y_var]['intercept']:.4f}\")\n",
    "        #         else:\n",
    "        #             print(f\"  USD_RUB importance: {results[y_var]['feature_importances']['USD_RUB']:.4f}\")\n",
    "        #             print(f\"  Brent importance: {results[y_var]['feature_importances']['Brent']:.4f}\")\n",
    "        #             print(f\"  BTC_USD importance: {results[y_var]['feature_importances']['BTC_USD']:.4f}\")\n",
    "        #         print(f\"  MAE: {results[y_var]['MAE']:.4f}\")\n",
    "        #         print(f\"  MSE: {results[y_var]['MSE']:.4f}\")\n",
    "        #     else:\n",
    "        #         print(f\"{y_var}: No model data available.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка в интерактивной визуализации: {e}\")\n",
    "\n",
    "# Sliders for real data\n",
    "usd_rub_slider_ruble = FloatSlider(\n",
    "    min=cleaned_df['USD_RUB'].min(), max=cleaned_df['USD_RUB'].max(), step=0.1,\n",
    "    value=cleaned_df['USD_RUB'].mean(), description='USD/RUB (руб):'\n",
    ")\n",
    "brent_slider_ruble = FloatSlider(\n",
    "    min=cleaned_df['Brent'].min(), max=cleaned_df['Brent'].max(), step=0.1,\n",
    "    value=cleaned_df['Brent'].mean(), description='Brent (долл.):'\n",
    ")\n",
    "btc_usd_slider_ruble = FloatSlider(\n",
    "    min=cleaned_df['BTC_USD'].min(), max=150000, step=100,\n",
    "    value=cleaned_df['BTC_USD'].mean(), description='BTC/USD (долл.):'\n",
    ")\n",
    "\n",
    "# Sliders for Z-normalized data\n",
    "btc_mean = cleaned_df['BTC_USD'].mean()\n",
    "btc_std = cleaned_df['BTC_USD'].std()\n",
    "btc_max_norm = (150000 - btc_mean) / btc_std\n",
    "btc_min_norm = (cleaned_df['BTC_USD'].min() - btc_mean) / btc_std\n",
    "\n",
    "usd_rub_slider_norm = FloatSlider(\n",
    "    min=normalized_df['USD_RUB'].min(), max=normalized_df['USD_RUB'].max(), step=0.1,\n",
    "    value=normalized_df['USD_RUB'].mean(), description='USD/RUB (Z):'\n",
    ")\n",
    "brent_slider_norm = FloatSlider(\n",
    "    min=normalized_df['Brent'].min(), max=normalized_df['Brent'].max(), step=0.1,\n",
    "    value=normalized_df['Brent'].mean(), description='Brent (Z):'\n",
    ")\n",
    "btc_usd_slider_norm = FloatSlider(\n",
    "    min=btc_min_norm, max=btc_max_norm, step=0.1,\n",
    "    value=normalized_df['BTC_USD'].mean(), description='BTC/USD (Z):'\n",
    ")\n",
    "\n",
    "# Dropdowns\n",
    "data_type_dropdown = Dropdown(\n",
    "    options=['Z-нормализованные', 'Реальные (рубли)'],\n",
    "    value='Реальные (рубли)',\n",
    "    description='Тип данных:'\n",
    ")\n",
    "model_type_dropdown = Dropdown(\n",
    "    options=['Линейная регрессия', 'Случайный лес'],\n",
    "    value='Линейная регрессия',\n",
    "    description='Модель:'\n",
    ")\n",
    "\n",
    "def update_sliders(data_type, model_type):\n",
    "    try:\n",
    "        if data_type == 'Z-нормализованные':\n",
    "            interact(\n",
    "                update_plot,\n",
    "                usd_rub=usd_rub_slider_norm,\n",
    "                brent=brent_slider_norm,\n",
    "                btc_usd=btc_usd_slider_norm,\n",
    "                data_type=fixed(data_type),\n",
    "                model_type=fixed(model_type)\n",
    "            )\n",
    "        else:\n",
    "            interact(\n",
    "                update_plot,\n",
    "                usd_rub=usd_rub_slider_ruble,\n",
    "                brent=brent_slider_ruble,\n",
    "                btc_usd=btc_usd_slider_ruble,\n",
    "                data_type=fixed(data_type),\n",
    "                model_type=fixed(model_type)\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"Error in update_sliders: {e}\")\n",
    "\n",
    "# First train the models\n",
    "results_normalized, results_normalized_rf = train_normalized_model()\n",
    "\n",
    "# Then run the interactive widget\n",
    "interact(update_sliders, data_type=data_type_dropdown, model_type=model_type_dropdown)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
